{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF552 Homework5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name : Hsin-Yu, Chang (1160173733)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Downloads the Anuran Calls (MFCCs) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00406/Anuran%20Calls%20(MFCCs).zip'\n",
    "zipname = \"Anuran Calls (MFCCs).zip\"\n",
    "#download a zip file from Web(URL)\n",
    "urllib.request.urlretrieve(url, zipname)\n",
    "mfcc = zipfile.ZipFile(zipname).open(\"Frogs_MFCCs.csv\")\n",
    "mfcc = pandas.read_csv(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccX = mfcc.iloc[:,:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccf = mfcc.Family\n",
    "mfccg = mfcc.Genus\n",
    "mfccs = mfcc.Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Leptodactylidae    4420\n",
       "Hylidae            2165\n",
       "Dendrobatidae       542\n",
       "Bufonidae            68\n",
       "Name: Family, dtype: int64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adenomera        4150\n",
       "Hypsiboas        1593\n",
       "Ameerega          542\n",
       "Dendropsophus     310\n",
       "Leptodactylus     270\n",
       "Scinax            148\n",
       "Osteocephalus     114\n",
       "Rhinella           68\n",
       "Name: Genus, dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdenomeraHylaedactylus    3478\n",
       "HypsiboasCordobae         1121\n",
       "AdenomeraAndre             672\n",
       "Ameeregatrivittata         542\n",
       "HypsiboasCinerascens       472\n",
       "HylaMinuta                 310\n",
       "LeptodactylusFuscus        270\n",
       "ScinaxRuber                148\n",
       "OsteocephalusOophagus      114\n",
       "Rhinellagranulosa           68\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Factorize the Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc.Family, categf = pandas.factorize(mfccf)\n",
    "mfcc.Genus, categg = pandas.factorize(mfccg)\n",
    "mfcc.Species, categs = pandas.factorize(mfccs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose 70% of the data randomly as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "traini = random.sample(range(mfcc.shape[0]), math.ceil(mfcc.shape[0]*0.7))\n",
    "traini.sort()\n",
    "testi = [i for i in range(mfcc.shape[0]) if i not in traini ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = mfcc.iloc[traini,:].reset_index(drop=True)\n",
    "test = mfcc.iloc[testi,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "colX = [col for col in ttrain.columns.tolist() if 'MFCCs_' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrainX = ttrain[colX]\n",
    "ttrainf = ttrain.Family\n",
    "ttraing = ttrain.Genus\n",
    "ttrains = ttrain.Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = test[colX]\n",
    "testf = test.Family\n",
    "testg = test.Genus\n",
    "tests = test.Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append(r'/anaconda3/pkgs/libsvm-3.23/python')\n",
    "sys.path.append(r'/anaconda3/pkgs/libsvm-3.23/tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svm\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from grid import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmlightfile(X, label):\n",
    "    dump_svmlight_file(X, label, 'mfcctrainL.dat', zero_based=True, multilabel=False)\n",
    "    mfcctrainL = load_svmlight_file('mfcctrainL.dat')\n",
    "    return mfcctrainL   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcctrainF = svmlightfile(ttrainX, ttrainf)\n",
    "mfcctrainG = svmlightfile(ttrainX, ttraing)\n",
    "mfcctrainS = svmlightfile(ttrainX, ttrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcctestF = svmlightfile(testX, testf)\n",
    "mfcctestG = svmlightfile(testX, testg)\n",
    "mfcctestS = svmlightfile(testX, tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Solving a multi-class and multi-label problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Exact Match Ratio and Hamming Loss for evaluating Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hamming Loss: the fraction of the wrong labels to the total number of labels\n",
    "- Exact Match Ratio: percentage of datapoints that have all their labels classified 100% correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabelleva(trueLabels, predLabels): #List of np.arrays of each label  \n",
    "    trueLabels = np.stack(trueLabels).T\n",
    "    predLabels = np.stack(predLabels).T\n",
    "    \n",
    "    #hamming loss\n",
    "    hammingloss = (sum(trueLabels[:,0]!=predLabels[:,0])+sum(trueLabels[:,1]!=predLabels[:,1])+sum(trueLabels[:,2]!=predLabels[:,2]))/(trueLabels.shape[0]*trueLabels.shape[1])\n",
    "    print('Hamming Loss: %0.3f'% hammingloss)\n",
    "    \n",
    "    #exact match score\n",
    "    trueLstr = np.array([str(int(trueLabels[i,0]))+str(int(trueLabels[i,1]))+str(int(trueLabels[i,2])) for i in range(trueLabels.shape[0])])\n",
    "    predLstr = np.array([str(int(predLabels[i,0]))+str(int(predLabels[i,1]))+str(int(predLabels[i,2])) for i in range(predLabels.shape[0])])\n",
    "    emr = sum(trueLstr== predLstr)/len(trueLstr)\n",
    "    print('Exact Match Ratio: %0.2f'% emr)\n",
    "    \n",
    "    return hammingloss, emr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. SVM for each of the labels with using Gaussian kernels and one versus all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpredLabelstr = [] # collecting label prediction from each label's classifier\n",
    "gpredLabelste = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use LIBSVM find the best C and gamma using 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramSearch(X, label):\n",
    "    dump_svmlight_file(X, label, 'mfcctrainL.dat', zero_based=True, multilabel=False)\n",
    "    mfcctrainL = load_svmlight_file('mfcctrainL.dat')\n",
    "    rate, param = find_parameters('mfcctrainL.dat', '-log2c -2,8,2 -log2g -5,3,2 -v 10')\n",
    "    return mfcctrainL, rate, param      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Family "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ Parameter-searching for C and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gnuplot executable not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[local] 4.0 -1.0 98.9081 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 0.0 -1.0 97.0419 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 4.0 -3.0 97.7566 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 0.0 -3.0 94.9176 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 8.0 -1.0 99.1066 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 8.0 -3.0 98.5507 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 4.0 3.0 98.9081 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 0.0 3.0 98.8485 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 8.0 3.0 98.9081 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] -2.0 -1.0 96.0889 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] -2.0 -3.0 93.6272 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] -2.0 3.0 98.0941 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 4.0 -5.0 95.1757 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 0.0 -5.0 93.1705 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 8.0 -5.0 97.7566 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] -2.0 -5.0 83.7006 (best c=256.0, g=0.5, rate=99.1066)\n",
      "[local] 6.0 -1.0 99.1463 (best c=64.0, g=0.5, rate=99.1463)\n",
      "[local] 6.0 -3.0 98.3323 (best c=64.0, g=0.5, rate=99.1463)\n",
      "[local] 6.0 3.0 98.9081 (best c=64.0, g=0.5, rate=99.1463)\n",
      "[local] 6.0 -5.0 96.9426 (best c=64.0, g=0.5, rate=99.1463)\n",
      "[local] 4.0 1.0 99.3448 (best c=16.0, g=2.0, rate=99.3448)\n",
      "[local] 0.0 1.0 99.1066 (best c=16.0, g=2.0, rate=99.3448)\n",
      "[local] 8.0 1.0 99.4044 (best c=256.0, g=2.0, rate=99.4044)\n",
      "[local] -2.0 1.0 98.3919 (best c=256.0, g=2.0, rate=99.4044)\n",
      "[local] 6.0 1.0 99.4044 (best c=64.0, g=2.0, rate=99.4044)\n",
      "[local] 2.0 -1.0 98.4912 (best c=64.0, g=2.0, rate=99.4044)\n",
      "[local] 2.0 -3.0 96.347 (best c=64.0, g=2.0, rate=99.4044)\n",
      "[local] 2.0 3.0 98.9081 (best c=64.0, g=2.0, rate=99.4044)\n",
      "[local] 2.0 -5.0 94.1632 (best c=64.0, g=2.0, rate=99.4044)\n",
      "[local] 2.0 1.0 99.2654 (best c=64.0, g=2.0, rate=99.4044)\n",
      "64.0 2.0 99.4044\n"
     ]
    }
   ],
   "source": [
    "mfcctrainF, ratef, paramf = paramSearch(ttrainX, ttrainf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "OvRsvc = OneVsRestClassifier(SVC(kernel='rbf', C=paramf['c'], gamma = paramf['g'], probability=True))\n",
    "optimalsvcF = OvRsvc.fit(ttrainX, mfcctrainF[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "sksvctrF = optimalsvcF.predict(ttrainX)\n",
    "gpredLabelstr.append(sksvctrF)\n",
    "sksvcteF = optimalsvcF.predict(testX)\n",
    "gpredLabelste.append(sksvcteF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Family' label on Training Set:\n",
      "[[3092    0    0    0]\n",
      " [   0  377    0    0]\n",
      " [   0    0 1522    0]\n",
      " [   0    0    0   46]]\n",
      "F1-score: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Family' label on Training Set:\") \n",
    "print(confusion_matrix(mfcctrainF[1], sksvctrF))\n",
    "print('F1-score: %0.3f' % f1_score(mfcctrainF[1], sksvctrF, average='weighted')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Family' label on Test Set:\n",
      "[[1321    1    6    0]\n",
      " [   0  164    1    0]\n",
      " [   4    0  639    0]\n",
      " [   2    0    3   17]]\n",
      "F1-score: 0.911\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Family' label on Test Set:\") \n",
    "print(confusion_matrix(mfcctestF[1], sksvcteF))\n",
    "print('F1-score: %0.3f' % f1_score(mfcctestF[1], sksvcteF, average='weighted')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Genus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ Parameter-searching for C and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gnuplot executable not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[local] 4.0 -1.0 98.9081 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 0.0 -1.0 97.3397 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 4.0 -3.0 97.8559 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 0.0 -3.0 93.8654 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 8.0 -1.0 98.8287 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 8.0 -3.0 98.65 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 4.0 3.0 98.3323 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 0.0 3.0 98.1338 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 8.0 3.0 98.3323 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] -2.0 -1.0 94.1036 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] -2.0 -3.0 89.7757 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] -2.0 3.0 96.7044 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 4.0 -5.0 95.7911 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 0.0 -5.0 89.6962 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 8.0 -5.0 97.7367 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] -2.0 -5.0 79.194 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 6.0 -1.0 98.8684 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 6.0 -3.0 98.511 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 6.0 3.0 98.3323 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 6.0 -5.0 97.2801 (best c=16.0, g=0.5, rate=98.9081)\n",
      "[local] 4.0 1.0 98.9478 (best c=16.0, g=2.0, rate=98.9478)\n",
      "[local] 0.0 1.0 98.789 (best c=16.0, g=2.0, rate=98.9478)\n",
      "[local] 8.0 1.0 99.0073 (best c=256.0, g=2.0, rate=99.0073)\n",
      "[local] -2.0 1.0 97.5978 (best c=256.0, g=2.0, rate=99.0073)\n",
      "[local] 6.0 1.0 99.0073 (best c=64.0, g=2.0, rate=99.0073)\n",
      "[local] 2.0 -1.0 98.4713 (best c=64.0, g=2.0, rate=99.0073)\n",
      "[local] 2.0 -3.0 96.7441 (best c=64.0, g=2.0, rate=99.0073)\n",
      "[local] 2.0 3.0 98.3323 (best c=64.0, g=2.0, rate=99.0073)\n",
      "[local] 2.0 -5.0 93.647 (best c=64.0, g=2.0, rate=99.0073)\n",
      "[local] 2.0 1.0 98.9279 (best c=64.0, g=2.0, rate=99.0073)\n",
      "64.0 2.0 99.0073\n"
     ]
    }
   ],
   "source": [
    "mfcctrainG, rateg, paramg = paramSearch(ttrainX, ttraing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "OvRsvc = OneVsRestClassifier(SVC(kernel='rbf', C=paramg['c'], gamma = paramg['g'], probability=True))\n",
    "#optimalsvc = GridSearchCV(OvRsvc, param_grid=parameters, cv=10, scoring='neg_log_loss')\n",
    "optimalsvcG = OvRsvc.fit(ttrainX, mfcctrainG[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "sksvctrG = optimalsvcG.predict(ttrainX)\n",
    "gpredLabelstr.append(sksvctrG)\n",
    "sksvcteG = optimalsvcG.predict(testX)\n",
    "gpredLabelste.append(sksvcteG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Genus' label on Training Set:\n",
      "[[2915    0    0    0    0    0    0    0]\n",
      " [   0  377    0    0    0    0    0    0]\n",
      " [   0    0  221    0    0    0    0    0]\n",
      " [   0    0    0 1116    0    0    0    0]\n",
      " [   0    0    0    0  177    0    0    0]\n",
      " [   0    0    0    0    0   80    0    0]\n",
      " [   0    0    0    0    0    0   46    0]\n",
      " [   0    0    0    0    0    0    0  105]]\n",
      "F1-score: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Genus' label on Training Set:\") \n",
    "print(confusion_matrix(mfcctrainG[1], sksvctrG))\n",
    "print('F1-score: %0.3f' % f1_score(mfcctrainG[1], sksvctrG, average='weighted')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Genus' label on Test Set:\n",
      "[[1229    1    2    1    0    1    0    1]\n",
      " [   0  165    0    0    0    0    0    0]\n",
      " [   5    0   84    0    0    0    0    0]\n",
      " [   1    0    0  473    0    2    0    1]\n",
      " [   0    0    0    1   92    0    0    0]\n",
      " [   1    0    0    1    0   32    0    0]\n",
      " [   2    0    0    1    1    0   18    0]\n",
      " [   0    0    0    0    0    0    0   43]]\n",
      "F1-score: 0.990\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Genus' label on Test Set:\") \n",
    "print(confusion_matrix(mfcctestG[1], sksvcteG))\n",
    "print('F1-score: %0.3f' % f1_score(mfcctestG[1], sksvcteG, average='weighted')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ Parameter-searching for C and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gnuplot executable not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[local] 4.0 -1.0 98.8684 (best c=16.0, g=0.5, rate=98.8684)\n",
      "[local] 0.0 -1.0 97.5978 (best c=16.0, g=0.5, rate=98.8684)\n",
      "[local] 4.0 -3.0 98.1934 (best c=16.0, g=0.5, rate=98.8684)\n",
      "[local] 0.0 -3.0 94.6595 (best c=16.0, g=0.5, rate=98.8684)\n",
      "[local] 8.0 -1.0 98.8088 (best c=16.0, g=0.5, rate=98.8684)\n",
      "[local] 8.0 -3.0 98.9279 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] 4.0 3.0 97.9353 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] 0.0 3.0 97.7765 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] 8.0 3.0 97.9353 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] -2.0 -1.0 94.7588 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] -2.0 -3.0 90.6095 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] -2.0 3.0 96.4264 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] 4.0 -5.0 96.9823 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] 0.0 -5.0 90.669 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] 8.0 -5.0 98.372 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] -2.0 -5.0 83.0256 (best c=256.0, g=0.125, rate=98.9279)\n",
      "[local] 6.0 -1.0 98.9676 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 6.0 -3.0 98.511 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 6.0 3.0 97.9353 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 6.0 -5.0 97.8956 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 4.0 1.0 98.8485 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 0.0 1.0 98.7493 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 8.0 1.0 98.789 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] -2.0 1.0 97.5184 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 6.0 1.0 98.789 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 2.0 -1.0 98.4713 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 2.0 -3.0 97.1213 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 2.0 3.0 97.9353 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 2.0 -5.0 94.7191 (best c=64.0, g=0.5, rate=98.9676)\n",
      "[local] 2.0 1.0 98.8882 (best c=64.0, g=0.5, rate=98.9676)\n",
      "64.0 0.5 98.9676\n"
     ]
    }
   ],
   "source": [
    "mfcctrainS, rates, params = paramSearch(ttrainX, ttrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "OvRsvc = OneVsRestClassifier(SVC(kernel='rbf', C=params['c'], gamma = params['g'], probability=True))\n",
    "#optimalsvc = GridSearchCV(OvRsvc, param_grid=parameters, cv=10, scoring='neg_log_loss')\n",
    "optimalsvcS = OvRsvc.fit(ttrainX, mfcctrainS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "sksvctrS = optimalsvcS.predict(ttrainX)\n",
    "gpredLabelstr.append(sksvctrS)\n",
    "sksvcteS = optimalsvcS.predict(testX)\n",
    "gpredLabelste.append(sksvcteS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Species' label on Training Set:\n",
      "[[ 462    0    0    1    0    0    0    0    0    0]\n",
      " [   0  377    0    0    0    0    0    0    0    0]\n",
      " [   0    0 2452    0    0    0    0    0    0    0]\n",
      " [   1    0    0  220    0    0    0    0    0    0]\n",
      " [   0    0    0    0  331    1    0    0    0    0]\n",
      " [   0    0    0    0    0  784    0    0    0    0]\n",
      " [   0    0    0    0    0    0  177    0    0    0]\n",
      " [   0    0    0    0    2    0    0   78    0    0]\n",
      " [   0    0    0    0    0    0    0    0   46    0]\n",
      " [   0    0    0    0    0    0    0    0    0  105]]\n",
      "F1-score: 0.999\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Species' label on Training Set:\") \n",
    "print(confusion_matrix(mfcctrainS[1], sksvctrS))\n",
    "print('F1-score: %0.3f' % f1_score(mfcctrainS[1], sksvctrS, average='weighted')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Species' label on Test Set:\n",
      "[[ 206    1    0    1    0    0    0    1    0    0]\n",
      " [   0  164    0    1    0    0    0    0    0    0]\n",
      " [   0    0 1024    1    0    0    0    0    0    1]\n",
      " [   1    0    3   85    0    0    0    0    0    0]\n",
      " [   1    0    0    0  136    0    0    3    0    0]\n",
      " [   0    0    0    0    0  334    0    2    0    1]\n",
      " [   0    0    0    0    1    0   92    0    0    0]\n",
      " [   1    0    0    0    0    0    0   33    0    0]\n",
      " [   3    0    1    0    0    0    1    0   17    0]\n",
      " [   0    0    0    0    0    0    0    0    0   43]]\n",
      "F1-score: 0.989\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Species' label on Test Set:\") \n",
    "print(confusion_matrix(mfcctestS[1], sksvcteS))\n",
    "print('F1-score: %0.3f' % f1_score(mfcctestS[1], sksvcteS, average='weighted')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueLabelstr = [mfcctrainF[1], mfcctrainG[1], mfcctrainS[1]]\n",
    "trueLabelste = [mfcctestF[1], mfcctestG[1], mfcctestS[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with OvR Gaussian kernels on Training Set\n",
      "Hamming Loss: 0.000\n",
      "Exact Match Ratio: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('SVM with OvR Gaussian kernels on Training Set')\n",
    "ghltr, gemrtr = multilabelleva(trueLabelstr, gpredLabelstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with OvR Gaussian kernels on Test Set\n",
      "Hamming Loss: 0.010\n",
      "Exact Match Ratio: 0.99\n"
     ]
    }
   ],
   "source": [
    "print('SVM with OvR Gaussian kernels on Test Set')\n",
    "ghlte, gemrte = multilabelleva(trueLabelste, gpredLabelste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation of ii. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ SVM with OvR Gaussian kernels has a good performance both on training and test set, even though there are class-inbalanced in each label, but this multilabel-multiclassifier have a high exact match ratio (closs to 100%) and a low lamming loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. L1-penalized SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1predLabelstr = []\n",
    "l1predLabelste = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path\n",
    "sys.path.append(r'/anaconda3/pkgs/liblinear-2.21/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import liblinear\n",
    "from liblinearutil import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ Parameter-searching for C in L1-penalized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1penalySVM(mfcctrainL):\n",
    "    acc = []\n",
    "    C = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "    parm = '-s 5 -v 10 -c '\n",
    "    for c in C:\n",
    "        acc.append(train(mfcctrainL[1], mfcctrainL[0], parm+str(c)))\n",
    "    bestC = np.array(C)[np.array(acc)==np.array(acc).max()][0]\n",
    "    model = train(mfcctrainL[1], mfcctrainL[0], '-s 5 -c '+str(bestC))\n",
    "    return bestC, model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def predictL1(svmfile, model):\n",
    "    predy, _, proby = predict(svmfile[1], svmfile[0], model)\n",
    "    print(confusion_matrix(svmfile[1], predy))\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    print('F1-score: %0.3f' % f1_score(svmfile[1], predy, average='weighted'))\n",
    "    return np.array(predy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 87.8301%\n",
      "Cross Validation Accuracy = 93.0713%\n",
      "Cross Validation Accuracy = 93.4683%\n",
      "Cross Validation Accuracy = 93.4286%\n",
      "Cross Validation Accuracy = 93.3691%\n",
      "Cross Validation Accuracy = 93.3492%\n",
      "Cross Validation Accuracy = 93.4485%\n",
      "Optimal C of L1-penalized for 'Family' Label: 1.00\n"
     ]
    }
   ],
   "source": [
    "bestCf, modelL1F = L1penalySVM(mfcctrainF)\n",
    "print(\"Optimal C of L1-penalized for 'Family' Label: %0.2f\" % bestCf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Family' label on Training Set:\n",
      "Accuracy = 93.6272% (4716/5037) (classification)\n",
      "[[3002   24   66    0]\n",
      " [   8  340   29    0]\n",
      " [ 130   18 1374    0]\n",
      " [   3    0   43    0]]\n",
      "F1-score: 0.932\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Family' label on Training Set:\") \n",
    "l1predLabelstr.append(predictL1(mfcctrainF, modelL1F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Family' label on Test Set:\n",
      "Accuracy = 93.6052% (2020/2158) (classification)\n",
      "[[1286   16   26    0]\n",
      " [   6  147   12    0]\n",
      " [  45   11  587    0]\n",
      " [   4    0   18    0]]\n",
      "F1-score: 0.931\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Family' label on Test Set:\") \n",
    "l1predLabelste.append(predictL1(mfcctestF, modelL1F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ L1-penalized SVM on 'Family' label has a problem on dealing with class-inbalance label, it missiclassifies most of 'Bufonidae' class to 'Hylidae' class, which is the second majority of 'Family' label.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 83.0256%\n",
      "Cross Validation Accuracy = 92.3963%\n",
      "Cross Validation Accuracy = 93.9647%\n",
      "Cross Validation Accuracy = 94.6794%\n",
      "Cross Validation Accuracy = 94.8978%\n",
      "Cross Validation Accuracy = 95.0169%\n",
      "Cross Validation Accuracy = 94.9772%\n",
      "Optimal C of L1-penalized for 'Genus' Label: 1000.00\n"
     ]
    }
   ],
   "source": [
    "bestCg, modelL1G = L1penalySVM(mfcctrainG)\n",
    "print(\"Optimal C of L1-penalized for 'Genus' Label: %0.2f\" % bestCg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Genus' label on Training Set:\n",
      "Accuracy = 95.3147% (4801/5037) (classification)\n",
      "[[2885   15    3   11    0    0    0    1]\n",
      " [   7  363    5    2    0    0    0    0]\n",
      " [  56    7  148   10    0    0    0    0]\n",
      " [  27    0    0 1083    4    0    0    2]\n",
      " [   3    0    4   17  152    1    0    0]\n",
      " [   3    0    0   31    0   46    0    0]\n",
      " [   5    0    0   17    1    0   23    0]\n",
      " [   1    0    0    3    0    0    0  101]]\n",
      "F1-score: 0.950\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Genus' label on Training Set:\") \n",
    "l1predLabelstr.append(predictL1(mfcctrainG, modelL1G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Genus' label on Test Set:\n",
      "Accuracy = 94.671% (2043/2158) (classification)\n",
      "[[1214   13    0    5    0    1    0    2]\n",
      " [   6  156    3    0    0    0    0    0]\n",
      " [  28    4   55    2    0    0    0    0]\n",
      " [   5    1    0  468    2    1    0    0]\n",
      " [   3    0    0    7   83    0    0    0]\n",
      " [   2    0    0   18    0   14    0    0]\n",
      " [   5    0    0    4    0    0   13    0]\n",
      " [   0    0    0    3    0    0    0   40]]\n",
      "F1-score: 0.943\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Genus' label on Test Set:\") \n",
    "l1predLabelste.append(predictL1(mfcctestG, modelL1G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 82.1322%\n",
      "Cross Validation Accuracy = 92.7536%\n",
      "Cross Validation Accuracy = 95.4139%\n",
      "Cross Validation Accuracy = 95.7713%\n",
      "Cross Validation Accuracy = 95.7713%\n",
      "Cross Validation Accuracy = 95.672%\n",
      "Cross Validation Accuracy = 95.5926%\n",
      "Optimal C of L1-penalized for 'Species' Label: 10.00\n"
     ]
    }
   ],
   "source": [
    "bestCs, modelL1S = L1penalySVM(mfcctrainS)\n",
    "print(\"Optimal C of L1-penalized for 'Species' Label: %0.2f\" % bestCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Species' label on Training Set:\n",
      "Accuracy = 96.1286% (4842/5037) (classification)\n",
      "[[ 439   14    0    1    0    7    0    0    0    2]\n",
      " [   2  364    0    6    1    2    0    2    0    0]\n",
      " [   0    1 2449    0    1    1    0    0    0    0]\n",
      " [  23    8   19  159    1   11    0    0    0    0]\n",
      " [   7    0    0    1  311   12    1    0    0    0]\n",
      " [   0    0    5    1    4  767    5    0    0    2]\n",
      " [   2    0    0    4    3    8  160    0    0    0]\n",
      " [   2    0    0    0   11   16    1   49    1    0]\n",
      " [   1    0    0    0    0    2    3    0   40    0]\n",
      " [   0    0    0    0    0    1    0    0    0  104]]\n",
      "F1-score: 0.960\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Species' label on Training Set:\") \n",
    "l1predLabelstr.append(predictL1(mfcctrainS, modelL1S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Species' label on Test Set:\n",
      "Accuracy = 95.8295% (2068/2158) (classification)\n",
      "[[ 193   10    0    0    0    5    0    1    0    0]\n",
      " [   3  157    0    4    0    0    0    1    0    0]\n",
      " [   0    0 1025    0    0    0    0    0    0    1]\n",
      " [   8    4   11   64    0    2    0    0    0    0]\n",
      " [   2    0    0    0  135    3    0    0    0    0]\n",
      " [   0    0    1    0    3  329    3    0    0    1]\n",
      " [   2    0    0    0    1    5   85    0    0    0]\n",
      " [   0    0    0    0    3    9    0   21    1    0]\n",
      " [   4    0    0    0    0    1    0    0   17    0]\n",
      " [   0    0    0    1    0    0    0    0    0   42]]\n",
      "F1-score: 0.957\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Species' label on Test Set:\") \n",
    "l1predLabelste.append(predictL1(mfcctestS, modelL1S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation of iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvR L1-penalized SVM on Training Set\n",
      "Hamming Loss: 0.050\n",
      "Exact Match Ratio: 0.92\n"
     ]
    }
   ],
   "source": [
    "print('OvR L1-penalized SVM on Training Set')\n",
    "l1hltr, l1emrtr = multilabelleva(trueLabelstr, l1predLabelstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvR L1-penalized SVM on Test Set\n",
      "Hamming Loss: 0.053\n",
      "Exact Match Ratio: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('OvR L1-penalized SVM on Test Set')\n",
    "l1hlte, l1emrte = multilabelleva(trueLabelste, l1predLabelste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ Each label classifier building on L1-penalized SVM has problem on misclassifying minority class, which makes this multi-label classifier have higher hamming loss and lower exact match ratio comparing to the RBF SVM classifier in question ii. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Remedy Class Imbalance on L1-penalized SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ To remedy class-imbalance in each label, I set class weights, with minority having higher cost weight when building classifer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl1predLabelstr = []\n",
    "wl1predLabelste = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ Balancing class weights in 'Family' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Leptodactylidae    4420\n",
       "Hylidae            2165\n",
       "Dendrobatidae       542\n",
       "Bufonidae            68\n",
       "Name: Family, dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Leptodactylidae', 'Dendrobatidae', 'Hylidae', 'Bufonidae'], dtype='object')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40695701,  3.31872694,  0.83083141, 26.45220588])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weightf = class_weight.compute_class_weight('balanced', np.unique(mfcc.Family), mfcc.Family)\n",
    "weightf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 82.2513%\n",
      "Cross Validation Accuracy = 91.6816%\n",
      "Cross Validation Accuracy = 93.0713%\n",
      "Cross Validation Accuracy = 93.111%\n",
      "Cross Validation Accuracy = 93.1705%\n",
      "Cross Validation Accuracy = 93.0911%\n",
      "Cross Validation Accuracy = 93.2698%\n",
      "Optimal C of L1-penalized for 'Family' Label on weighting: 10000.00\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "C = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "parm = '-s 5 -w0 0.4 -w1 3 -w2 0.8 -w3 26 -v 10 -c '\n",
    "for c in C:\n",
    "    acc.append(train(mfcctrainF[1], mfcctrainF[0], parm+str(c)))\n",
    "sbestCf = np.array(C)[np.array(acc)==np.array(acc).max()][0]\n",
    "smodelF = train(mfcctrainF[1], mfcctrainF[0], '-s 5 -w0 0.4 -w1 3 -w2 0.8 -w3 26 -c '+str(sbestCf))\n",
    "print(\"Optimal C of L1-penalized for 'Family' Label on weighting: %0.2f\" % sbestCf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Family' label on Training Set:\n",
      "Accuracy = 93.3889% (4704/5037) (classification)\n",
      "[[2944   45   79   24]\n",
      " [   6  365    5    1]\n",
      " [ 100   41 1354   27]\n",
      " [   3    0    2   41]]\n",
      "F1-score: 0.936\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Family' label on Training Set:\") \n",
    "wl1predLabelstr.append(predictL1(mfcctrainF, smodelF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Family' label on Test Set:\n",
      "Accuracy = 93.6052% (2020/2158) (classification)\n",
      "[[1264   27   31    6]\n",
      " [   2  156    6    1]\n",
      " [  37   17  582    7]\n",
      " [   3    0    1   18]]\n",
      "F1-score: 0.937\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Family' label on Test Set:\") \n",
    "wl1predLabelste.append(predictL1(mfcctestF, smodelF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ With weighting, the model on 'Family' label performs better classification in the minority class comparing to previous model, especially on the 'Bufonidae' class, which has mostly been misclassified to 'Hylidae' without weighting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adenomera        4150\n",
       "Hypsiboas        1593\n",
       "Ameerega          542\n",
       "Dendropsophus     310\n",
       "Leptodactylus     270\n",
       "Scinax            148\n",
       "Osteocephalus     114\n",
       "Rhinella           68\n",
       "Name: Genus, dtype: int64"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Adenomera', 'Ameerega', 'Dendropsophus', 'Hypsiboas', 'Leptodactylus',\n",
       "       'Osteocephalus', 'Rhinella', 'Scinax'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21671687,  1.65936347,  2.90120968,  0.56457941,  3.33101852,\n",
       "        7.88925439, 13.22610294,  6.07685811])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightg = class_weight.compute_class_weight('balanced', np.unique(mfcc.Genus), mfcc.Genus)\n",
    "weightg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 82.3705%\n",
      "Cross Validation Accuracy = 93.786%\n",
      "Cross Validation Accuracy = 94.4014%\n",
      "Cross Validation Accuracy = 94.3816%\n",
      "Cross Validation Accuracy = 94.3816%\n",
      "Cross Validation Accuracy = 94.5801%\n",
      "Cross Validation Accuracy = 94.4213%\n",
      "Optimal C of L1-penalized for 'Genus' Label on weighting: 1000.00\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "C = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "parm = '-s 5 -w0 0.2 -w1 1.6 -w2 3 -w3 0.5 -w4 3 -w5 8 -w6 13 -w7 6 -v 10 -c '\n",
    "for c in C:\n",
    "    acc.append(train(mfcctrainG[1], mfcctrainG[0], parm+str(c)))\n",
    "sbestCg = np.array(C)[np.array(acc)==np.array(acc).max()][0]\n",
    "smodelG = train(mfcctrainG[1], mfcctrainG[0], '-s 5 -w0 0.2 -w1 1.6 -w2 3 -w3 0.5 -w4 3 -w5 8 -w6 13 -w7 6 -c '+str(sbestCg))\n",
    "print(\"Optimal C of L1-penalized for 'Genus' Label on weighting: %0.2f\" % sbestCg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Genus' label on Training Set:\n",
      "Accuracy = 94.9772% (4784/5037) (classification)\n",
      "[[2815   38   30   13    0    9    8    2]\n",
      " [   4  354   17    1    0    0    1    0]\n",
      " [  27    6  176    6    0    0    5    1]\n",
      " [  16    0    2 1072   11    7    6    2]\n",
      " [   0    0    5   10  160    1    1    0]\n",
      " [   0    0    0   10    0   65    5    0]\n",
      " [   1    0    0    1    2    0   42    0]\n",
      " [   0    0    0    0    0    0    5  100]]\n",
      "F1-score: 0.951\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Genus' label on Training Set:\") \n",
    "wl1predLabelstr.append(predictL1(mfcctrainG, smodelG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Genus' label on Test Set:\n",
      "Accuracy = 94.8563% (2047/2158) (classification)\n",
      "[[1188   26    6    5    0    6    2    2]\n",
      " [   1  155    8    0    0    0    1    0]\n",
      " [  16    3   67    0    0    0    3    0]\n",
      " [   4    0    0  463    3    5    0    2]\n",
      " [   0    0    0    5   86    0    2    0]\n",
      " [   0    0    0    5    0   27    2    0]\n",
      " [   3    0    0    1    0    0   18    0]\n",
      " [   0    0    0    0    0    0    0   43]]\n",
      "F1-score: 0.949\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Genus' label on Test Set:\") \n",
    "wl1predLabelste.append(predictL1(mfcctestG, smodelG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ The 'Genus' model with a weighting remedy performs not only better classification on 'Osteocephalus' class comparing to previous model, which has been misclassified to 'Leptodactylus' class without weighting, but also a better classification on 'Dendropsophus' class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label- Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdenomeraHylaedactylus    3478\n",
       "HypsiboasCordobae         1121\n",
       "AdenomeraAndre             672\n",
       "Ameeregatrivittata         542\n",
       "HypsiboasCinerascens       472\n",
       "HylaMinuta                 310\n",
       "LeptodactylusFuscus        270\n",
       "ScinaxRuber                148\n",
       "OsteocephalusOophagus      114\n",
       "Rhinellagranulosa           68\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AdenomeraAndre', 'Ameeregatrivittata', 'AdenomeraHylaedactylus',\n",
       "       'HylaMinuta', 'HypsiboasCinerascens', 'HypsiboasCordobae',\n",
       "       'LeptodactylusFuscus', 'OsteocephalusOophagus', 'Rhinellagranulosa',\n",
       "       'ScinaxRuber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07068452,  1.32749077,  0.20687177,  2.32096774,  1.52436441,\n",
       "        0.64183764,  2.66481481,  6.31140351, 10.58088235,  4.86148649])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(mfcc.Species), mfcc.Species)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 86.2617%\n",
      "Cross Validation Accuracy = 95.0169%\n",
      "Cross Validation Accuracy = 95.6125%\n",
      "Cross Validation Accuracy = 95.8309%\n",
      "Cross Validation Accuracy = 95.6323%\n",
      "Cross Validation Accuracy = 95.811%\n",
      "Cross Validation Accuracy = 95.6125%\n",
      "Optimal C of L1-penalized for 'Species' Label on weighting: 10.00\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "C = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "parm = '-s 5 -w0 1 -w1 1 -w2 0.2 -w3 2.3 -w4 1.5 -w5 0.6 -w6 2.6 -w7 6 -w8 10 -w9 5 -v 10 -c '\n",
    "for c in C:\n",
    "    acc.append(train(mfcctrainS[1], mfcctrainS[0], parm+str(c)))\n",
    "sbestCs = np.array(C)[np.array(acc)==np.array(acc).max()][0]\n",
    "smodelS = train(mfcctrainS[1], mfcctrainS[0], '-s 5 -w0 1 -w1 1 -w2 0.2 -w3 2.3 -w4 1.5 -w5 0.6 -w6 2.6 -w7 6 -w8 10 -w9 5 -c '+str(sbestCg))\n",
    "print(\"Optimal C of L1-penalized for 'Species' Label on weighting: %0.2f\" % sbestCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Species' label on Training Set:\n",
      "Accuracy = 96.3073% (4851/5037) (classification)\n",
      "[[ 433   14    0    6    0    3    0    3    1    3]\n",
      " [   2  350    0   18    1    1    0    3    2    0]\n",
      " [   0    2 2447    0    1    1    0    0    1    0]\n",
      " [  16    6    9  179    1    4    0    0    5    1]\n",
      " [   5    0    0    1  312    6    2    4    2    0]\n",
      " [   1    0    5    1    6  760    7    0    2    2]\n",
      " [   1    0    0    4    2    4  164    1    1    0]\n",
      " [   1    0    0    0    6    6    1   62    4    0]\n",
      " [   0    0    0    0    0    0    2    0   44    0]\n",
      " [   0    0    0    0    0    0    0    0    5  100]]\n",
      "F1-score: 0.963\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Species' label on Training Set:\") \n",
    "wl1predLabelstr.append(predictL1(mfcctrainS, smodelS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of 'Species' label on Test Set:\n",
      "Accuracy = 95.5978% (2063/2158) (classification)\n",
      "[[ 192   10    0    0    1    2    0    3    0    1]\n",
      " [   2  154    0    7    0    0    0    1    1    0]\n",
      " [   0    0 1020    3    1    0    0    0    0    2]\n",
      " [   7    3   10   67    0    1    0    0    1    0]\n",
      " [   2    0    0    0  134    1    1    2    0    0]\n",
      " [   0    0    1    0    4  323    3    3    1    2]\n",
      " [   0    0    0    0    1    3   87    0    2    0]\n",
      " [   0    0    0    0    2    5    1   25    1    0]\n",
      " [   3    0    0    0    0    1    0    0   18    0]\n",
      " [   0    0    0    0    0    0    0    0    0   43]]\n",
      "F1-score: 0.956\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of 'Species' label on Test Set:\") \n",
    "wl1predLabelste.append(predictL1(mfcctestS, smodelS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ In 'Species' class, class imbalance does not cause large problem in previous model with f1-score = 0.957 on test set, but in this exercise, I still use weighting remedy to fix the class imbalance in the 'Species' label, but both accuracy and f1-score do not seem better than previous model without weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation of iv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvR L1-penalized SVM on Training Set with weighting\n",
      "Hamming Loss: 0.051\n",
      "Exact Match Ratio: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('OvR L1-penalized SVM on Training Set with weighting')\n",
    "wl1hltr, wl1emrtr = multilabelleva(trueLabelstr, wl1predLabelstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvR L1-penalized SVM on Test Set with weighting\n",
      "Hamming Loss: 0.053\n",
      "Exact Match Ratio: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('OvR L1-penalized SVM on Test Set with weighting')\n",
    "wl1hlte, wl1emrte = multilabelleva(trueLabelste, wl1predLabelste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __>__ Conclusion of Model Selection on the Anuran Calls (MFCCs) Data Set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Multi-class and Multi-label data set, comparing this three model based on exact match Ratio and hamming loss, SVM with Gaussian kernel and OvR classifiers has an outstanding performance with exact match ratio = 0.99 and hamming loss = 0.01.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) K-means Clustering with optimal k based on Silhouettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "def silhouettescore(n_clusters, X, rs):\n",
    "    silhouettescore = []\n",
    "    for clus in range(2, n_clusters+5):\n",
    "        clusterer = KMeans(n_clusters=clus, random_state = rs)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        silhouettescore.append(silhouette_score(X, cluster_labels))\n",
    "    silhouettescore = np.array(silhouettescore)\n",
    "    \n",
    "#     return [np.array([clus for clus in range(2, n_clusters+5)])[silhouettescore==max(silhouettescore)]\n",
    "#             , max(silhouettescore)]\n",
    "    return int(np.array([clus for clus in range(2, n_clusters+5)])[silhouettescore==max(silhouettescore)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Label Majority in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustormajority(cluster_labels, label):\n",
    "    clustermajority = []\n",
    "    cluster = list(set(cluster_labels))\n",
    "    cluster.sort()\n",
    "    for c in cluster:\n",
    "        #nparray index\n",
    "        index, = np.where(cluster_labels == c)\n",
    "        incluster = label[index]\n",
    "        incluster = incluster.tolist()\n",
    "        clustermajority.append(max(set(incluster), key = incluster.count))\n",
    "    clustermajority = pandas.Series(clustermajority)\n",
    "    return clustermajority    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusLabel(cluster_labels, clusmaj):\n",
    "    clabel = np.empty(len(cluster_labels), dtype=\"U20\")\n",
    "    cluster = list(set(cluster_labels))\n",
    "    for c in cluster:\n",
    "        #nparray index\n",
    "        index, = np.where(cluster_labels == c)\n",
    "        clabel[index] = clusmaj[c]\n",
    "    return clabel    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__>__ Demo of one simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k based on Silhouettes: 4 \n",
      "\n",
      "\n",
      "Family Label for each cluster:\n",
      "0    Leptodactylidae\n",
      "1      Dendrobatidae\n",
      "2            Hylidae\n",
      "3            Hylidae\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Genus Label for each cluster:\n",
      "0    Adenomera\n",
      "1     Ameerega\n",
      "2    Hypsiboas\n",
      "3    Hypsiboas\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Species Label for each cluster:\n",
      "0    AdenomeraHylaedactylus\n",
      "1        Ameeregatrivittata\n",
      "2      HypsiboasCinerascens\n",
      "3         HypsiboasCordobae\n",
      "dtype: object\n",
      "\n",
      "\n",
      "hamming loss= 0.38\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 10\n",
    "demooptimalclus = silhouettescore(n_clusters, mfccX, 0) \n",
    "print('Best k based on Silhouettes: %d ' %demooptimalclus)\n",
    "democlusterer = KMeans(n_clusters=demooptimalclus, random_state = 0)\n",
    "democluster_labels = democlusterer.fit_predict(mfccX)\n",
    "        \n",
    "democlusmaj1 = clustormajority(democluster_labels, mfccf)\n",
    "print('\\n')  \n",
    "print('Family Label for each cluster:')\n",
    "print(democlusmaj1)\n",
    "\n",
    "democlusmaj2 = clustormajority(democluster_labels, mfccg)\n",
    "print('\\n')  \n",
    "print('Genus Label for each cluster:')\n",
    "print(democlusmaj2)\n",
    "\n",
    "democlusmaj3 = clustormajority(democluster_labels, mfccs)\n",
    "print('\\n')  \n",
    "print('Species Label for each cluster:')\n",
    "print(democlusmaj3)\n",
    "        \n",
    "democlusLabel1 = clusLabel(democluster_labels, democlusmaj1)\n",
    "democlusLabel2 = clusLabel(democluster_labels, democlusmaj2)\n",
    "democlusLabel3 = clusLabel(democluster_labels, democlusmaj3)\n",
    "print('\\n')        \n",
    "print('hamming loss= %0.2f' % ((sum(mfccf != democlusLabel1)+sum(mfccg != democlusLabel2)+sum(mfccs != democlusLabel3))/(mfccX.shape[0]*3)))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __>__ Function of whole Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonteCarlo(n, X, label1, label2, label3):\n",
    "    hamming = []\n",
    "    n_clusters = 10\n",
    "    for i in range(n):\n",
    "        optimalclus = silhouettescore(n_clusters, X, i) \n",
    "        #print(optimalclus)\n",
    "        clusterer = KMeans(n_clusters=optimalclus, random_state = i)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        \n",
    "        clusmaj1 = clustormajority(cluster_labels, label1)\n",
    "        print(clusmaj1)\n",
    "        clusmaj2 = clustormajority(cluster_labels, label2)\n",
    "        print(clusmaj2)\n",
    "        clusmaj3 = clustormajority(cluster_labels, label3)\n",
    "        print(clusmaj3)\n",
    "        \n",
    "        clusLabel1 = clusLabel(cluster_labels, clusmaj1)\n",
    "        clusLabel2 = clusLabel(cluster_labels, clusmaj2)\n",
    "        clusLabel3 = clusLabel(cluster_labels, clusmaj3)\n",
    "        \n",
    "        hammingloss = (sum(label1 != clusLabel1)+sum(label2 != clusLabel2)+sum(label3 != clusLabel3))/(X.shape[0]*3)\n",
    "        hamming.append(hammingloss) \n",
    "    return np.array(hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCsimulation = MonteCarlo(50, mfccX, mfccf, mfccg, mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38248784, 0.38299745, 0.40583739, 0.38299745, 0.38299745,\n",
       "       0.38299745, 0.38299745, 0.38299745, 0.38299745, 0.38299745,\n",
       "       0.38299745, 0.38299745, 0.38299745, 0.38299745, 0.38299745,\n",
       "       0.38304378, 0.38299745, 0.3943016 , 0.38299745, 0.38234885,\n",
       "       0.3946259 , 0.38299745, 0.38299745, 0.38304378, 0.38299745,\n",
       "       0.38299745, 0.38299745, 0.38304378, 0.38299745, 0.38299745,\n",
       "       0.38299745, 0.38299745, 0.38299745, 0.38299745, 0.34681492,\n",
       "       0.38299745, 0.38299745, 0.38299745, 0.38299745, 0.38299745,\n",
       "       0.38299745, 0.38299745, 0.38299745, 0.38299745, 0.38299745,\n",
       "       0.38299745, 0.38299745, 0.38299745, 0.44063007, 0.38299745])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCsimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Hamming Loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3843"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Average Hamming Loss')\n",
    "round(MCsimulation.mean(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error of Hamming Loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0103"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Standard Error of Hamming Loss')\n",
    "round(MCsimulation.std(),4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
